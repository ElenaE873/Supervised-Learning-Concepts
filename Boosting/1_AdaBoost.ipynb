{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5349a0cc",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90954614",
   "metadata": {},
   "source": [
    "- Training ensemble of predictors sequencially for the purpose of the predictor to try to correct the errors of the predecessor predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9048e9a4",
   "metadata": {},
   "source": [
    "### AdaBoost - \"Adaptive Boosting\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a421a5cf",
   "metadata": {},
   "source": [
    "- Changes the weights of training instances\n",
    "\n",
    "Classification\n",
    "- weighted majority voting via **AdaBoostClassifier**\n",
    "\n",
    "Regression\n",
    "- weighted average via **AdaBoostRegressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cc49d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED=1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                    stratify=y,\n",
    "                                                   random_state=SEED)\n",
    "\n",
    "dt= DecisionTreeClassifier(max_depth=1, random_state=SEED)\n",
    "adb_clf = AdaBoostClassifier(base_estimator=dt, n_estimators=100)\n",
    "\n",
    "adb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_proba = adb_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "adb_clf_roc_auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print('ROC AUC Score: {:.2f}'.format(adb_clf_roc_auc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b645ea",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b31651",
   "metadata": {},
   "source": [
    "- unlike AdaBoost, the weights of training instances are not tweaked.\n",
    "- sequential correction of predecessor's errors\n",
    "- fit each predictor is trained using residual errors as labels\n",
    "- Gradient Boosted Trees - a CART used as a BASE LEARNER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278c22e1",
   "metadata": {},
   "source": [
    "- Classification: **GradientBoostingClassifier**\n",
    "- Regression: **GradientBoostingRegressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba6f405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "SEED=1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                    stratify=y,\n",
    "                                                   random_state=SEED)\n",
    "\n",
    "gbt = GradientBoostingRegressor(n_estimators=300,\n",
    "                               max_depth=1,\n",
    "                               random_seed=SEED)\n",
    "\n",
    "gbt.fit(X_train, y_train)\n",
    "y_pred = gbt.predict(X_test)\n",
    "\n",
    "rmse_test = (MSE(y_test, y_pred))**(1/2)\n",
    "print('test set RMSE of rf: {:.2f}'.format(rmse_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814e0510",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162ab9fa",
   "metadata": {},
   "source": [
    "- each tree is trained on a random subset of rows of the training data\n",
    "- 40-80% of sampled instances are sampled without replacement\n",
    "- features are sampled without replacements when choosing split points\n",
    "- **this results in adding further variance to the ensemble of trees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be267e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "SEED=1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                    stratify=y,\n",
    "                                                   random_state=SEED)\n",
    "\n",
    "sgbt = GradientBoostingRegressor(max_depth=1,\n",
    "                                subsample=0.8,\n",
    "                                max_features,\n",
    "                                n_estimators=300,\n",
    "                                random_state=SEED)\n",
    "\n",
    "sgbt.fit(X_train, y_train)\n",
    "y_pred = sgbt.predict(X_test)\n",
    "\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "print('Test set RMSE: {:.2f}'.format(rmse_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
